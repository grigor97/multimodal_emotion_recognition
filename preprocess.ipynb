{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import re\n",
    "import math\n",
    "import pandas as pd\n",
    "# import pdb\n",
    "\n",
    "import librosa\n",
    "import os\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "import matplotlib.style as ms\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "import IPython.display\n",
    "import librosa.display\n",
    "ms.use('seaborn-muted')\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iemocap_full_release_path = \"/Users/grigorkeropyan/Desktop/YSU_thesis/small_data/IEMOCAP_full_release/\"\n",
    "\n",
    "iemocap_pre_processed_data_path = \"/Users/grigorkeropyan/Desktop/YSU_thesis/small_data/pre_processed_data/iemocap/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_line = re.compile(r'\\[.+\\]\\n', re.IGNORECASE)\n",
    "\n",
    "start_times, end_times, wav_file_names, emotions, vals, acts, doms = [], [], [], [], [], [], []\n",
    "\n",
    "for sess in range(1, 2):\n",
    "    emo_evaluation_dir = iemocap_full_release_path + '/Session{}/dialog/EmoEvaluation/'.format(sess)\n",
    "    evaluation_files = [l for l in os.listdir(emo_evaluation_dir) if 'Ses' in l]\n",
    "    for file in evaluation_files:\n",
    "        x = re.search(\"^Ses.*\", file)\n",
    "        if x == None:\n",
    "            continue\n",
    "        with open(emo_evaluation_dir + file) as f:\n",
    "            content = f.read()\n",
    "        info_lines = re.findall(info_line, content)\n",
    "        for line in info_lines[1:]:  # the first line is a header\n",
    "            #pdb.set_trace()   \n",
    "            start_end_time, wav_file_name, emotion, val_act_dom = line.strip().split('\\t')\n",
    "            start_time, end_time = start_end_time[1:-1].split('-')\n",
    "            val, act, dom = val_act_dom[1:-1].split(',')\n",
    "            val, act, dom = float(val), float(act), float(dom)\n",
    "            start_time, end_time = float(start_time), float(end_time)\n",
    "            start_times.append(start_time)\n",
    "            end_times.append(end_time)\n",
    "            wav_file_names.append(wav_file_name)\n",
    "            emotions.append(emotion)\n",
    "            vals.append(val)\n",
    "            acts.append(act)\n",
    "            doms.append(dom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_iemocap = pd.DataFrame(columns=['start_time', 'end_time', 'wav_file', 'emotion', 'val', 'act', 'dom'])\n",
    "\n",
    "df_iemocap['start_time'] = start_times\n",
    "df_iemocap['end_time'] = end_times\n",
    "df_iemocap['wav_file'] = wav_file_names\n",
    "df_iemocap['emotion'] = emotions\n",
    "df_iemocap['val'] = vals\n",
    "df_iemocap['act'] = acts\n",
    "df_iemocap['dom'] = doms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iemocap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr = 44100\n",
    "audio_vectors = {}\n",
    "\n",
    "for sess in [1]:  # using one session due to memory constraint, can replace [5] with range(1, 6)\n",
    "    wav_file_path = '{}/Session{}/dialog/wav/'.format(iemocap_full_release_path, sess)\n",
    "    #pdb.set_trace()\n",
    "    orig_wav_files = os.listdir(wav_file_path)\n",
    "    \n",
    "#     print(orig_wav_files)\n",
    "    for orig_wav_file in tqdm(orig_wav_files):\n",
    "        #print(\"Wav file is \", orig_wav_file)\n",
    "        x = re.search(\"^Ses.*\", orig_wav_file)\n",
    "        if '.DS_Store' == orig_wav_file:\n",
    "            continue\n",
    "        if x == None:\n",
    "            print(\"Skiping file\", orig_wav_file)\n",
    "            continue\n",
    "#         print(wav_file_path + orig_wav_file)\n",
    "        try:\n",
    "            orig_wav_vector, _sr = librosa.load(wav_file_path + orig_wav_file, sr=sr)\n",
    "\n",
    "            orig_wav_file, file_format = orig_wav_file.split('.')\n",
    "            print(\"Working on file - \", orig_wav_file)\n",
    "            #pdb.set_trace()\n",
    "            for index, row in df_iemocap[df_iemocap['wav_file'].str.contains(orig_wav_file)].iterrows():\n",
    "                start_time, end_time, truncated_wav_file_name, emotion, val, act, dom = row['start_time'], row['end_time'], row['wav_file'], row['emotion'], row['val'], row['act'], row['dom']\n",
    "                start_frame = math.floor(start_time * sr)\n",
    "                end_frame = math.floor(end_time * sr)\n",
    "                truncated_wav_vector = orig_wav_vector[start_frame:end_frame + 1]\n",
    "\n",
    "\n",
    "                X = librosa.stft(truncated_wav_vector)\n",
    "                Xdb = librosa.amplitude_to_db(abs(X))\n",
    "                plt.figure(figsize=(14, 5))\n",
    "                #plt.figure()\n",
    "                librosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='hz')\n",
    "                plt.colorbar()\n",
    "\n",
    "                #pdb.set_trace()\n",
    "                plt.savefig(iemocap_pre_processed_data_path + \"images/\" + str(emotion) +\"_\"+ str(val) +\"_\"+ str(act) +\"_\"+ str(dom) + '.png')\n",
    "                plt.close('all')\n",
    "                audio_vectors[truncated_wav_file_name] = truncated_wav_vector\n",
    "\n",
    "        except:\n",
    "            print('An exception occured for {}'.format(orig_wav_file))\n",
    "    with open(iemocap_pre_processed_data_path + '/audio_vectors_exp_{}.pkl'.format(sess), 'wb') as f:\n",
    "        pickle.dump(audio_vectors, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../small_data/pre_processed_data/audio_vectors_exp_1.pkl\", 'rb') as file:\n",
    "    d = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(d[list(d.keys())[-3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iemocap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../small_data/pre_processed_data/iemocap/df_iemocap.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.file_path[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.file_path[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(df.emotion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ems = ['ang', 'exc', 'fru', 'hap', 'neu', 'sur']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'an' in ems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ems = ['ang', 'hap', 'sad', 'fea', 'sur', 'neu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "enterfece_data_path = \"/Users/grigorkeropyan/Desktop/YSU_thesis/small_data/enterface_database\"\n",
    "pre_processed_data_path = '/Users/grigorkeropyan/Desktop/YSU_thesis/small_data/pre_processed_data/enterface'\n",
    "# pre_processed_data_path = \"/home/student/keropyan/data/pre_processed_data/iemocap/\"\n",
    "# subject_num = 44\n",
    "# subject_num = 2\n",
    "\n",
    "emo_conv_dict = {\n",
    "    'fear': 'fea',\n",
    "    'surprise': 'sur',\n",
    "    'sadness': 'sad',\n",
    "    'happiness': 'hap',\n",
    "    'anger': 'ang',\n",
    "    'disgust': 'dis',\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_enterface_paths(enterfece_data_path):\n",
    "    video_paths = []\n",
    "    emotions = []\n",
    "    for subject in os.listdir(enterfece_data_path):\n",
    "        if subject == '.DS_Store':\n",
    "            continue\n",
    "    #     print(subject)\n",
    "        sub_path = enterfece_data_path + '/' + subject\n",
    "        for emotion in os.listdir(sub_path):\n",
    "            if emotion == '.DS_Store':\n",
    "                continue\n",
    "            emo_path = sub_path + '/' + emotion\n",
    "\n",
    "            for sent in os.listdir(emo_path):\n",
    "                if sent == '.DS_Store':\n",
    "                    continue\n",
    "\n",
    "                sent_path = emo_path + '/' + sent\n",
    "                paths = glob(sent_path + '/' + '*.avi')\n",
    "                for p in paths:\n",
    "                    video_paths.append(p)\n",
    "                    emotions.append(emo_conv_dict[emotion])\n",
    "\n",
    "    df_enterface = pd.DataFrame(columns=['file_path', 'emotion'])\n",
    "\n",
    "    df_enterface['file_path'] = video_paths\n",
    "    df_enterface['emotion'] = emotions\n",
    "\n",
    "    df_enterface.to_csv(pre_processed_data_path + '/df_enterface.csv', index=False)\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_enterface_paths(enterfece_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(pre_processed_data_path+'/df_enterface.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.file_path[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ravdess_data_path = '/Users/grigorkeropyan/Desktop/YSU_thesis/small_data/RAVDESS'\n",
    "pre_processed_data_path = '/Users/grigorkeropyan/Desktop/YSU_thesis/small_data/pre_processed_data/RAVDESS'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ravdess_paths(ravdess_data_path, pre_processed_data_path):\n",
    "    emotions = []\n",
    "    actors = []\n",
    "    video_paths = []\n",
    "    for actor in os.listdir(ravdess_data_path):\n",
    "        if actor == '.DS_Store':\n",
    "            continue\n",
    "        act_path = ravdess_data_path + '/' + actor\n",
    "\n",
    "\n",
    "        ps = glob(act_path + '/' + '*.mp4')\n",
    "        for p in ps:\n",
    "            vals = p.split('/')[-1].split('.')[0].split('-')\n",
    "            #filtering only videos with audio\n",
    "            if vals[0] != '01':\n",
    "                continue\n",
    "            actors.append(vals[-1])\n",
    "            video_paths.append(p)\n",
    "            emotions.append(vals[2])\n",
    "\n",
    "    df_ravdess = pd.DataFrame(columns=['file_path', 'emotion', 'actor'])\n",
    "\n",
    "    df_ravdess['file_path'] = video_paths\n",
    "    df_ravdess['emotion'] = emotions\n",
    "    df_ravdess['actor'] = actors\n",
    "\n",
    "    df_ravdess.to_csv(pre_processed_data_path + '/df_ravdess.csv', index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ravdess_paths(ravdess_data_path, pre_processed_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(pre_processed_data_path + '/df_ravdess.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_path</th>\n",
       "      <th>emotion</th>\n",
       "      <th>actor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Users/grigorkeropyan/Desktop/YSU_thesis/small...</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Users/grigorkeropyan/Desktop/YSU_thesis/small...</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/Users/grigorkeropyan/Desktop/YSU_thesis/small...</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/Users/grigorkeropyan/Desktop/YSU_thesis/small...</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/Users/grigorkeropyan/Desktop/YSU_thesis/small...</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>/Users/grigorkeropyan/Desktop/YSU_thesis/small...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>/Users/grigorkeropyan/Desktop/YSU_thesis/small...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>/Users/grigorkeropyan/Desktop/YSU_thesis/small...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>/Users/grigorkeropyan/Desktop/YSU_thesis/small...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>/Users/grigorkeropyan/Desktop/YSU_thesis/small...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             file_path  emotion  actor\n",
       "0    /Users/grigorkeropyan/Desktop/YSU_thesis/small...        3     10\n",
       "1    /Users/grigorkeropyan/Desktop/YSU_thesis/small...        3     10\n",
       "2    /Users/grigorkeropyan/Desktop/YSU_thesis/small...        2     10\n",
       "3    /Users/grigorkeropyan/Desktop/YSU_thesis/small...        1     10\n",
       "4    /Users/grigorkeropyan/Desktop/YSU_thesis/small...        2     10\n",
       "..                                                 ...      ...    ...\n",
       "115  /Users/grigorkeropyan/Desktop/YSU_thesis/small...        3      3\n",
       "116  /Users/grigorkeropyan/Desktop/YSU_thesis/small...        3      3\n",
       "117  /Users/grigorkeropyan/Desktop/YSU_thesis/small...        2      3\n",
       "118  /Users/grigorkeropyan/Desktop/YSU_thesis/small...        2      3\n",
       "119  /Users/grigorkeropyan/Desktop/YSU_thesis/small...        1      3\n",
       "\n",
       "[120 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml1",
   "language": "python",
   "name": "ml1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
